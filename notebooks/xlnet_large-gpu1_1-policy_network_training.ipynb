{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facebook-bart-large'\n",
    "cuda_device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(BaseNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.layers = []\n",
    "        i = 0\n",
    "        for s1, s2 in zip(args.sizes[:-1], args.sizes[1:]):\n",
    "            self.layers.append(nn.Linear(s1, s2))\n",
    "            self.register_parameter('weight-layer-' + str(i), self.layers[-1].weight)\n",
    "            self.register_parameter('bias-layer-' + str(i), self.layers[-1].bias)\n",
    "            nn.init.xavier_uniform_(self.layers[-1].weight)\n",
    "            i += 1\n",
    "        self.nl = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = self.nl(layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSpecificNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, args, task_metadata=None):\n",
    "        super(TaskSpecificNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.base_network = BaseNetwork(args)\n",
    "        self.out_layers = []\n",
    "        i = 0\n",
    "        for task in args.class_tasks:\n",
    "            self.out_layers.append(nn.Linear(args.sizes[-1], task))\n",
    "            self.register_parameter('out-weight-layer-' + str(i), self.out_layers[-1].weight)\n",
    "            self.register_parameter('out-bias-layer-' + str(i), self.out_layers[-1].bias)\n",
    "            nn.init.xavier_uniform_(self.out_layers[-1].weight)\n",
    "            i += 1\n",
    "        self.nl = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x, task_id):\n",
    "        rep_x = self.base_network(x)\n",
    "        x = self.out_layers[task_id](self.nl(rep_x))\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return rep_x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSpecificNetworkMultilabel(nn.Module):\n",
    "    \n",
    "    def __init__(self, args, task_metadata=None):\n",
    "        super(TaskSpecificNetworkMultilabel, self).__init__()\n",
    "        self.args = args\n",
    "        self.base_network = BaseNetwork(args)\n",
    "        self.out_layers = []\n",
    "        i = 0\n",
    "        for task, task_type in zip(args.class_tasks, args.class_types):\n",
    "            self.out_layers.append(nn.Linear(args.sizes[-1], task))\n",
    "            self.register_parameter('out-weight-layer-' + str(i), self.out_layers[-1].weight)\n",
    "            self.register_parameter('out-bias-layer-' + str(i), self.out_layers[-1].bias)\n",
    "            nn.init.xavier_uniform_(self.out_layers[-1].weight)\n",
    "            i += 1\n",
    "        self.nl = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x, task_id):\n",
    "        rep_x = self.base_network(x)\n",
    "        x = self.out_layers[task_id](self.nl(rep_x))\n",
    "        if self.args.class_types[task_id] == 'classification':\n",
    "            out = F.softmax(x, dim=1)\n",
    "        elif self.args.class_types[task_id] == 'multilabel':\n",
    "            out = torch.sigmoid(x)\n",
    "        return rep_x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.actor = nn.Linear(args.state_dim, 2)\n",
    "        nn.init.xavier_uniform_(self.actor.weight)\n",
    "        self.nl = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        action_probs = F.softmax(self.actor(x), dim=-1)\n",
    "        return action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.actor = nn.Linear(args.state_dim, 2)\n",
    "        nn.init.xavier_uniform_(self.actor.weight)\n",
    "        self.nl = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        action_probs = F.softmax(self.actor(x), dim=-1)\n",
    "        return action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.task_model = TaskSpecificNetworkMultilabel(args)\n",
    "        self.ff1 = nn.Linear(args.state_dim, args.hdim)\n",
    "        nn.init.xavier_uniform_(self.ff1.weight)\n",
    "        self.critic_layer = nn.Linear(args.hdim, 1)\n",
    "        nn.init.xavier_uniform_(self.critic_layer.weight)\n",
    "        self.nl = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out = self.task_model.base_network(x).detach()\n",
    "        c_in = self.nl(self.ff1(x_out))\n",
    "        out = torch.sigmoid(self.critic_layer(c_in))\n",
    "        out = torch.mean(out)\n",
    "        return x_out, out\n",
    "    \n",
    "    def task_output(self, x, task_id):\n",
    "        return self.task_model(x, task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.actor = ActorNetwork(args)\n",
    "        self.critic = CriticNetwork(args)\n",
    "        self.task_optims = []\n",
    "        self.loss_fns = []\n",
    "        \n",
    "        for i in range(args.num_tasks):\n",
    "            params = []\n",
    "            base_params = [p for p in self.critic.task_model.base_network.parameters() if p.requires_grad]\n",
    "            task_params = [p for p in self.critic.task_model.out_layers[i].parameters() if p.requires_grad]\n",
    "            params = base_params + task_params\n",
    "            self.task_optims.append(optim.Adam(params, lr=args.lr))\n",
    "            if args.class_types[i] == 'classification':\n",
    "                if args.use_cuda:\n",
    "                    with torch.cuda.device(cuda_device):\n",
    "                        args.loss_weights[i] = args.loss_weights[i].cuda()\n",
    "                self.loss_fns.append(nn.CrossEntropyLoss(weight=args.loss_weights[i]))\n",
    "            elif args.class_types[i] == 'multilabel':\n",
    "                self.loss_fns.append(nn.BCELoss())\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def forward(self, batch_x):\n",
    "        if self.args.use_cuda:\n",
    "            with torch.cuda.device(cuda_device):\n",
    "                batch_x = batch_x.cuda()\n",
    "        batch_rep, exp_reward = self.critic(batch_x)\n",
    "        action_probs = self.actor(batch_rep)\n",
    "        return action_probs, batch_rep, exp_reward\n",
    "        \n",
    "    def compute_reward(self, eval_data):\n",
    "        pred_ys = []\n",
    "        data_ys = []\n",
    "        for eval_batch in eval_data:\n",
    "            batch_x, batch_y = eval_batch\n",
    "            if self.args.use_cuda:\n",
    "                with torch.cuda.device(cuda_device):\n",
    "                    batch_x = batch_x.cuda()\n",
    "                    batch_y = batch_y.cuda()\n",
    "            _, pred_out = self.critic.task_output(batch_x, -1)\n",
    "            if self.args.class_types[-1] == 'classification':\n",
    "                pred_y = torch.argmax(pred_out, dim=1)\n",
    "            elif self.args.class_types[-1] == 'multilabel':\n",
    "                pred_y = (pred_out >= 0.5).long()\n",
    "            pred_ys.append(pred_y)\n",
    "            data_ys.append(batch_y)\n",
    "        pred_Y = torch.cat(pred_ys, dim=0)\n",
    "        data_Y = torch.cat(data_ys, dim=0)\n",
    "        f1_ma = float(f1_score(data_Y.cpu().data, pred_Y.cpu().data, average='macro'))\n",
    "        return f1_ma\n",
    "        \n",
    "    def train_minibatch(self, batch_x, batch_y, task_id):\n",
    "        if self.args.use_cuda:\n",
    "            with torch.cuda.device(cuda_device):\n",
    "                batch_x = batch_x.cuda()\n",
    "                batch_y = batch_y.cuda()\n",
    "        _, batch_out = self.critic.task_output(batch_x, task_id)\n",
    "        batch_loss = self.loss_fns[task_id](batch_out, batch_y)\n",
    "        self.critic.task_model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        self.task_optims[task_id].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.finfo(np.float32).eps.item()\n",
    "def finish_episode(policy_model, data_sets, eval_data):\n",
    "    \n",
    "    for dnum, dset in enumerate(data_sets):\n",
    "        train, dev, test = dset\n",
    "        for train_batch in train:\n",
    "            batch_x, batch_y = train_batch\n",
    "            action_probs, batch_rep, exp_reward = policy_model(batch_x)\n",
    "            m = Categorical(action_probs)\n",
    "            action = m.sample()\n",
    "            batch_mask = action.cpu() == torch.ones(action.size())\n",
    "            sel_x = batch_x[batch_mask, :]\n",
    "            sel_y = batch_y[batch_mask]\n",
    "            policy_model.train_minibatch(sel_x, sel_y, dnum)\n",
    "            reward = policy_model.compute_reward(eval_data)\n",
    "            policy_model.saved_actions.append((m.log_prob(action), exp_reward))\n",
    "            policy_model.rewards.append(reward)\n",
    "            \n",
    "        policy_losses = []\n",
    "        value_losses = []\n",
    "\n",
    "        R_mean = np.mean(policy_model.rewards)\n",
    "        R_std = np.std(policy_model.rewards)\n",
    "        for i, r in enumerate(policy_model.rewards):\n",
    "            policy_model.rewards[i] = float((r - R_mean) / (R_std + eps))\n",
    "\n",
    "        for (log_prob, value), R in zip(policy_model.saved_actions, policy_model.rewards):\n",
    "            advantage = R - value.item()\n",
    "\n",
    "            # calculate actor (policy) loss \n",
    "            policy_losses.append(-log_prob * advantage)\n",
    "\n",
    "            # calculate critic (value) loss using L1 smooth loss\n",
    "            R_tensor = torch.tensor([R])\n",
    "            if policy_model.args.use_cuda:\n",
    "                with torch.cuda.device(cuda_device):\n",
    "                    R_tensor = R_tensor.cuda()\n",
    "            value_losses.append(F.smooth_l1_loss(value.view(1,), R_tensor))\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # sum up all the values of policy_losses and value_losses\n",
    "        loss = torch.cat(policy_losses, dim=0).sum() + torch.stack(value_losses).sum()\n",
    "\n",
    "        # perform backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset rewards and action buffer\n",
    "        del policy_model.rewards[:]\n",
    "        del policy_model.saved_actions[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_mtl_epoch(mtl_model, data_sets, eval_data):\n",
    "    for dnum, dset in enumerate(data_sets):\n",
    "        train, dev, test = dset\n",
    "        for train_batch in train:\n",
    "            batch_x, batch_y = train_batch\n",
    "            mtl_model.train_minibatch(batch_x, batch_y, dnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sizes = [300, 500, 100]\n",
    "        self.hdim = 50\n",
    "        self.state_dim = 100\n",
    "        self.class_tasks = [2, 2, 2, 2, 2]\n",
    "        self.num_tasks = 5\n",
    "        self.lr = 1e-2\n",
    "        self.use_cuda = True\n",
    "        self.class_types = ['classification'] * 5\n",
    "        \n",
    "args1 = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['jigsaw-dataset', 'hate-speech-dataset', 'hate-speech-and-offensive-language', 'ami-ibereval-dataset', 'stereotype'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "dpath = '/scratch1/rpujari/gcr_workspace/data/'\n",
    "with open(dpath + 'batched_dsets_multilabel_' + model_name + 'bsz64.pkl', 'rb') as infile:\n",
    "    batched_dsets = pickle.load(infile)\n",
    "print(batched_dsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = []\n",
    "for label in batched_dsets:\n",
    "    if label != 'stereotype':\n",
    "        dsets.append(batched_dsets[label])\n",
    "dsets.append(batched_dsets['stereotype'])\n",
    "trimmed_dsets = []\n",
    "nbatches = 300 #Change to 2000 to run experiments on full data \n",
    "for dset in dsets:\n",
    "    trimmed_dsets.append((dset[0][:nbatches], dset[1][:nbatches], dset[2][:nbatches]))\n",
    "edata = batched_dsets['ami-ibereval-dataset'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jigsaw-dataset 1995\n",
      "hate-speech-dataset 120\n",
      "hate-speech-and-offensive-language 271\n",
      "ami-ibereval-dataset 36\n",
      "stereotype 263\n"
     ]
    }
   ],
   "source": [
    "for dname in batched_dsets:\n",
    "    print(dname, len(batched_dsets[dname][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tasks = [6, 2, 3, 2, 2]\n",
    "num_tasks = 5\n",
    "lr = 3e-5\n",
    "class_types = ['multilabel', 'classification', 'classification', 'classification', 'classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670 {0: 1471, 1: 199}\n",
      "0.10647405029427502\n",
      "3746 {1: 2905, 2: 624, 0: 217}\n",
      "0.2911842830652032\n",
      "502 {1: 264, 0: 238}\n",
      "0.34464751958224543\n",
      "3478 {0: 2219, 1: 1259}\n",
      "0.26578002955457036\n"
     ]
    }
   ],
   "source": [
    "#computing loss weights based on class distributions in the training data\n",
    "o = 0\n",
    "l = 0\n",
    "loss_weights = [None]\n",
    "for dnum, dset in enumerate(trimmed_dsets):\n",
    "    if dnum > 0:\n",
    "        tr, de, te = dset\n",
    "        ldict = {}\n",
    "        t = 0\n",
    "        loss_weight = torch.ones(class_tasks[dnum]).float()\n",
    "        data_ys = []\n",
    "        for batch in de:\n",
    "    #         print(batch[1].size())\n",
    "            for i in range(batch[1].size(0)):\n",
    "                if batch[1][i].data.item() not in ldict:\n",
    "                    ldict[batch[1][i].data.item()] = 0\n",
    "                ldict[batch[1][i].data.item()] += 1\n",
    "                t += 1\n",
    "            data_ys.append(batch[1])\n",
    "        data_y = torch.cat(data_ys, dim=0)\n",
    "        pred_y = torch.ones(data_y.size())\n",
    "        print(t, ldict)\n",
    "        for i in range(class_tasks[dnum]):\n",
    "            loss_weight[i] = t / ldict[i]\n",
    "        loss_weights.append(loss_weight)\n",
    "        f1_ma = f1_score(data_y.cpu().data, pred_y.cpu().data, average='macro') \n",
    "        print(f1_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, sizes, use_cuda, lr, momentum, weight_decay, loss_weight):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.layers = []\n",
    "        i = 0\n",
    "        for s1, s2 in zip(sizes[:-1], sizes[1:]):\n",
    "            self.layers.append(nn.Linear(s1, s2))\n",
    "            self.register_parameter('weight-layer-' + str(i), self.layers[-1].weight)\n",
    "            self.register_parameter('bias-layer-' + str(i), self.layers[-1].bias)\n",
    "            nn.init.xavier_uniform_(self.layers[-1].weight)\n",
    "            i += 1\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "        self.nl = nn.Tanh()\n",
    "        params = [p for p in self.parameters() if p.requires_grad]\n",
    "        self.optimizer = optim.Adam(params, lr=lr)\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = self.nl(layer(x))\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out\n",
    "        \n",
    "    def evaluate(self, data):\n",
    "        self.eval()\n",
    "        batch_outs = []\n",
    "        batch_preds = []\n",
    "        batch_ys = []\n",
    "        for batch_x, batch_y in data:\n",
    "            if self.use_cuda:\n",
    "                with torch.cuda.device(cuda_device):\n",
    "                    batch_x = batch_x.cuda()\n",
    "                    batch_y = batch_y.cuda()\n",
    "            batch_out = self.forward(batch_x)\n",
    "            batch_pred = torch.argmax(batch_out, dim=1)\n",
    "            batch_outs.append(batch_out)\n",
    "            batch_preds.append(batch_pred)\n",
    "            batch_ys.append(batch_y)\n",
    "        pred_y = torch.cat(batch_preds, dim=0)\n",
    "        data_y = torch.cat(batch_ys, dim=0)\n",
    "        pred_out = torch.cat(batch_outs, dim=0)\n",
    "        acc = sum((pred_y == data_y).float()) / data_y.size(0)\n",
    "        f1_mi = f1_score(data_y.cpu().data, pred_y.cpu().data, average='micro')\n",
    "        f1_ma = f1_score(data_y.cpu().data, pred_y.cpu().data, average='macro')\n",
    "        con_mat = confusion_matrix(data_y.cpu().data, pred_y.cpu().data)\n",
    "        val_loss = self.loss_fn(pred_out, data_y)\n",
    "        return acc.cpu(), val_loss.cpu(), (f1_mi, f1_ma, con_mat)\n",
    "        \n",
    "    def train_model(self, train, val, num_epochs=25, save_path='./model.pkl'):\n",
    "        self.train()\n",
    "        for i in range(num_epochs):\n",
    "            max_val = -1\n",
    "            for batch_x, batch_y in train:\n",
    "                if self.use_cuda:\n",
    "                    with torch.cuda.device(cuda_device):\n",
    "                        batch_x = batch_x.cuda()\n",
    "                        batch_y = batch_y.cuda()\n",
    "                ids = list(range(batch_x.size(0)))\n",
    "                random.shuffle(ids)\n",
    "                batch_x = batch_x[ids, :]\n",
    "                batch_y = batch_y[ids]\n",
    "                batch_out = self.forward(batch_x)\n",
    "                loss = self.loss_fn(batch_out, batch_y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            val_acc, val_loss, (f1_mi, f1_ma, cm) = self.evaluate(val)\n",
    "            if f1_ma > max_val:\n",
    "                max_val = f1_ma\n",
    "                torch.save(self.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args2():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.edim = 1024\n",
    "        self.tdim = 300\n",
    "        self.hdim = 50\n",
    "        self.ddim = 20\n",
    "        self.num_deps = 78\n",
    "        self.padding_idx = 0\n",
    "        self.sizes = [1024, 300, 100, 2]\n",
    "        self.use_cuda = True\n",
    "        self.lr = 3e-5\n",
    "        self.momentum = 0.1\n",
    "        self.weight_decay = 0\n",
    "        self.device = cuda_device\n",
    "        self.loss_weight = torch.from_numpy(np.array([1., 1.])).type(torch.FloatTensor)\n",
    "        \n",
    "args2 = Args2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1024, 300, 100, 2]\n",
      "0.5717471772303054 0:00:22.237974 \n",
      "\n",
      "[1024, 300, 100, 3]\n",
      "0.4540735866182117 0:01:09.511269 \n",
      "\n",
      "[1024, 300, 100, 2]\n",
      "0.6061129151024252 0:01:16.227762 \n",
      "\n",
      "[1024, 300, 100, 2]\n",
      "0.6262672507943621 0:01:56.381867 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "num_epochs = 100\n",
    "for i in range(1, len(trimmed_dsets)):\n",
    "    dset = trimmed_dsets[i]\n",
    "    tr, de, te = dset\n",
    "    torch.manual_seed(13)\n",
    "    args2.sizes[-1] = class_tasks[i]\n",
    "    args2.loss_weight = loss_weights[i]\n",
    "    print(args2.sizes)\n",
    "    model = FeedForward(args2.sizes, args2.use_cuda, args2.lr, args2.momentum, args2.weight_decay, args2.loss_weight)\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        model.cuda(cuda_device)\n",
    "\n",
    "    de = dset[1]\n",
    "    te = dset[2]\n",
    "    model.train_model(tr, de, num_epochs=num_epochs, save_path=dpath + 'trained_models/base_model' + str(i) + '_' + model_name + '.pkl')\n",
    "    model.load_state_dict(torch.load(dpath + 'trained_models/base_model' + str(i) + '_' + model_name + '.pkl'))\n",
    "    res = model.evaluate(de)\n",
    "#     con_mat = res[-1][-1]\n",
    "#     acc = res[0]\n",
    "#     prec_1 = con_mat[1, 1] / (con_mat[1, 1] + con_mat[0, 1])\n",
    "#     rec_1 = con_mat[1, 1] / (con_mat[1, 1] + con_mat[1, 0])\n",
    "#     f1_1 = 2 * prec_1 * rec_1 / (prec_1 + rec_1)\n",
    "    t2 = datetime.now()\n",
    "    print(res[2][1], t2 - t1, '\\n')#, (round(acc.data.item(), 4), round(prec_1, 4), round(rec_1, 4), round(f1_1, 4)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args1.sizes = [1024, 300, 100]\n",
    "args1.class_tasks = [6, 2, 3, 2, 2]\n",
    "args1.num_tasks = 5\n",
    "args1.lr = 3e-5\n",
    "args1.class_types = ['multilabel', 'classification', 'classification', 'classification', 'classification']\n",
    "args1.loss_weights = loss_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46670950676893264\n",
      "211 1648 0.12803398058252427\n",
      "Test Performance -  1 :  0.5963610175733979 0:04:02.817876 \n",
      "\n",
      "\n",
      "0.21875870009219686\n",
      "4115 3712 1.1085668103448276\n",
      "Test Performance -  2 :  0.47279802631471685 0:08:12.488411 \n",
      "\n",
      "\n",
      "0.445126151381658\n",
      "225 498 0.45180722891566266\n",
      "Test Performance -  3 :  0.5824495737159492 0:12:27.231444 \n",
      "\n",
      "\n",
      "0.4762084306365222\n",
      "1276 3610 0.35346260387811634\n",
      "Test Performance -  4 :  0.6857974107269882 0:16:44.239686 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "num_ep = 200\n",
    "\n",
    "#For each dataset in the set of datasets\n",
    "for i in range(1, len(trimmed_dsets)):\n",
    "    \n",
    "    #evaluation dataset - dev data of selected dataset i\n",
    "    edata = trimmed_dsets[i][1]\n",
    "    #test dataset - test data of selected dataset i\n",
    "    tdata = trimmed_dsets[i][2]\n",
    "    \n",
    "    #create arguments by excluding the dataset in focus\n",
    "    sample_dsets = trimmed_dsets[:i] + trimmed_dsets[i+1:]# + trimmed_dsets[i]\n",
    "    args1.class_tasks = class_tasks[:i] + class_tasks[i+1:]# + class_tasks[i]\n",
    "    args1.class_types = class_types[:i] + class_types[i+1:]# + class_types[i]\n",
    "    args1.loss_weights = loss_weights[:i] + loss_weights[i+1:]# + loss_weights[i]\n",
    "    args1.num_tasks = len(sample_dsets)\n",
    "    args1.prefix = '_p1_dset' + str(i) + '_' + model_name \n",
    "    \n",
    "    #initialize a multi-task model\n",
    "    torch.manual_seed(13)\n",
    "    random.seed(13)\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        model = PolicyNetwork(args1)\n",
    "        model.cuda(cuda_device)\n",
    "        optimizer = optim.Adadelta(model.parameters(), args1.lr)\n",
    "    \n",
    "    #Train on all datasets - dataset i, with eval data as the dev data of the last dataset\n",
    "    max_reward = -1\n",
    "    max_epoch = -1\n",
    "    for epoch in range(num_ep):\n",
    "        finish_mtl_epoch(model, sample_dsets, edata)\n",
    "        t2 = datetime.now()\n",
    "        Re = model.compute_reward(sample_dsets[-1][1])\n",
    "        if Re > max_reward:\n",
    "            torch.save(model.state_dict(), dpath + 'trained_models/mtl_model' + args1.prefix + '.pkl')\n",
    "            max_reward = Re\n",
    "            max_epoch = epoch\n",
    "#         print('Epoch', epoch, Re, t2-t1)\n",
    "    \n",
    "    #create arguments with only dataset i\n",
    "    sample_dsets = [trimmed_dsets[i]]\n",
    "    args1.class_tasks = [class_tasks[i]]\n",
    "    args1.class_types = [class_types[i]]\n",
    "    args1.loss_weights = [loss_weights[i]]\n",
    "    args1.num_tasks = len(sample_dsets)\n",
    "    args1.prefix = '_p2_dset' + str(i) + '_' + model_name \n",
    "    \n",
    "    #initialize a new model for just task i\n",
    "    torch.manual_seed(13)\n",
    "    random.seed(13)\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        model = PolicyNetwork(args1)\n",
    "        model.cuda(cuda_device)\n",
    "        optimizer = optim.Adadelta(model.parameters(), args1.lr)\n",
    "    \n",
    "    #extract the base network parameters from the trained multi-task model\n",
    "    state_dict = torch.load(dpath + 'trained_models/mtl_model_p1_dset' + str(i) + '_' + model_name + '.pkl')\n",
    "    del_keys = []\n",
    "    for key in state_dict:\n",
    "        if key.startswith('critic.task_model.out-'):\n",
    "            del_keys.append(key)\n",
    "    for key in del_keys:\n",
    "        del state_dict[key]\n",
    "    #initialize with best model from multi-task learning phase and evaluate the model on dataset i\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    print(model.compute_reward(edata))\n",
    "    \n",
    "    #train the model with training data - train data i and eval data as dev data i\n",
    "    max_reward = -1\n",
    "    max_epoch = -1\n",
    "    for epoch in range(num_ep):\n",
    "        finish_mtl_epoch(model, sample_dsets, edata)\n",
    "        t2 = datetime.now()\n",
    "        Re = model.compute_reward(edata)\n",
    "        if Re > max_reward:\n",
    "            torch.save(model.state_dict(), dpath + 'trained_models/mtl_model' + args1.prefix + '.pkl')\n",
    "            max_reward = Re\n",
    "            max_epoch = epoch\n",
    "#         print('Epoch', epoch, Re, t2-t1)\n",
    "    \n",
    "    #load best model parameters and evluate the traine model\n",
    "    model.load_state_dict(torch.load(dpath + 'trained_models/mtl_model' + args1.prefix + '.pkl'))\n",
    "    o = 0\n",
    "    l = 0\n",
    "    for batch in tdata:\n",
    "        o += torch.sum(batch[1]).data.item()\n",
    "        l += len(batch[1])\n",
    "    print(o, l, o/l)\n",
    "    t2 = datetime.now()\n",
    "    print('Test Performance - ', i, ': ', model.compute_reward(edata), t2-t1, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5806905031760894\n",
      "211 1648 0.12803398058252427\n",
      "Test Performance -  1 :  0.5760629112931797 0:26:30.356505 \n",
      "\n",
      "\n",
      "0.46456490251260485\n",
      "4115 3712 1.1085668103448276\n",
      "Test Performance -  2 :  0.473264962789864 1:20:58.228438 \n",
      "\n",
      "\n",
      "0.5709812942285267\n",
      "225 498 0.45180722891566266\n",
      "Test Performance -  3 :  0.5856351608388262 1:36:40.073597 \n",
      "\n",
      "\n",
      "0.680348173113854\n",
      "1276 3610 0.35346260387811634\n",
      "Test Performance -  4 :  0.6850467901315358 2:48:28.480076 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "num_ep = 100\n",
    "\n",
    "#For each dataset in the set of datasets\n",
    "for i in range(1, len(trimmed_dsets)):\n",
    "    \n",
    "    #evaluation dataset - dev data of selected dataset i\n",
    "    edata = trimmed_dsets[i][1]\n",
    "    #test dataset - test data of selected dataset i\n",
    "    tdata = trimmed_dsets[i][2]\n",
    "    \n",
    "    #create arguments by placing the target dataset as the last task\n",
    "    sample_dsets = trimmed_dsets[:i] + trimmed_dsets[i+1:] + [trimmed_dsets[i]]\n",
    "    args1.class_tasks = class_tasks[:i] + class_tasks[i+1:] + [class_tasks[i]]\n",
    "    args1.class_types = class_types[:i] + class_types[i+1:] + [class_types[i]]\n",
    "    args1.loss_weights = loss_weights[:i] + loss_weights[i+1:] + [loss_weights[i]]\n",
    "    args1.num_tasks = len(sample_dsets)\n",
    "    args1.prefix = '_p3_dset' + str(i) + '_' + model_name \n",
    "    \n",
    "    #initialize the policy network\n",
    "    torch.manual_seed(13)\n",
    "    random.seed(13)\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        model = PolicyNetwork(args1)\n",
    "        model.cuda(cuda_device)\n",
    "        optimizer = optim.Adadelta(model.parameters(), args1.lr)\n",
    "    \n",
    "    #extract the task model parameters from the trained multi-task models\n",
    "    state_dict2 = torch.load(dpath + 'trained_models/mtl_model_p2_dset' + str(i) + '_' + model_name + '.pkl')\n",
    "    state_dict1 = torch.load(dpath + 'trained_models/mtl_model_p1_dset' + str(i) + '_' + model_name + '.pkl')\n",
    "    state_dict = model.state_dict()\n",
    "    \n",
    "    done = -1\n",
    "    #initialize all the sister task parameters from stage 1 mtl model\n",
    "    for key in state_dict1:\n",
    "        if key.startswith('critic.task_model.out-'):\n",
    "            task_id = int(key.split('-')[-1])\n",
    "            if task_id > done:\n",
    "                done = task_id\n",
    "            state_dict[key] = state_dict1[key]\n",
    "    #initialize target task parameters from stage 2 mtl model\n",
    "    for key in state_dict2:\n",
    "        if key.startswith('critic.task_model.out-'):\n",
    "            ksplit = key.split('-')\n",
    "            #change the target task id from 0 (in stage 2 mtl model) to (num_tasks - 1)\n",
    "            ksplit[-1] = str(done + 1)\n",
    "            state_dict['-'.join(ksplit)] = state_dict2[key]\n",
    "        elif key.startswith('critic.task_model'):\n",
    "            state_dict[key] = state_dict2[key]\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    #Train RL model on all datasets, with eval data - dev data of target task ( dataset i)\n",
    "    max_reward = -1\n",
    "    max_epoch = -1\n",
    "    for epoch in range(num_ep):\n",
    "        finish_episode(model, sample_dsets, edata)\n",
    "        t2 = datetime.now()\n",
    "        Re = model.compute_reward(edata)\n",
    "        if Re > max_reward:\n",
    "            torch.save(model.state_dict(), dpath + 'trained_models/rl_model' + args1.prefix + '.pkl')\n",
    "            max_reward = Re\n",
    "            max_epoch = epoch\n",
    "#         print('Epoch', epoch, Re, t2-t1)\n",
    "    \n",
    "    #create arguments for dataset i\n",
    "    sample_dsets = [trimmed_dsets[i]]\n",
    "    args1.class_tasks = [class_tasks[i]]\n",
    "    args1.class_types = [class_types[i]]\n",
    "    args1.loss_weights = [loss_weights[i]]\n",
    "    args1.num_tasks = len(sample_dsets)\n",
    "    args1.prefix = '_p4_dset' + str(i) + '_' + model_name \n",
    "    \n",
    "    #initialize a new model for just task i\n",
    "    torch.manual_seed(13)\n",
    "    random.seed(13)\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        model = PolicyNetwork(args1)\n",
    "        model.cuda(cuda_device)\n",
    "        optimizer = optim.Adadelta(model.parameters(), args1.lr)\n",
    "    \n",
    "    #extract the parameters of target task from stage 3 RL model\n",
    "    state_dict = torch.load(dpath + 'trained_models/rl_model_p3_dset' + str(i) + '_' + model_name + '.pkl')\n",
    "    del_keys = []\n",
    "    #remove paramters of other tasks from state_dict\n",
    "    for key in state_dict:\n",
    "        if key.startswith('critic.task_model.out-'):\n",
    "            del_keys.append(key)\n",
    "    for key in del_keys:\n",
    "        if not key.endswith(str(done + 1)):\n",
    "            del state_dict[key]\n",
    "    for key in del_keys:\n",
    "        if key.endswith(str(done + 1)):\n",
    "            #rename target task paramters from num_tasks-1 to 0 \n",
    "            ksplit = key.split('-')\n",
    "            ksplit[-1] = '0'\n",
    "            state_dict['-'.join(ksplit)] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "            \n",
    "    #initialize with best model from stage 3 and evaluate the model on dev data of dataset i\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(model.compute_reward(edata))\n",
    "    \n",
    "    #train the model on target task\n",
    "    max_reward = -1\n",
    "    max_epoch = -1\n",
    "    for epoch in range(num_ep):\n",
    "        finish_episode(model, sample_dsets, edata)\n",
    "        t2 = datetime.now()\n",
    "        Re = model.compute_reward(edata)\n",
    "        if Re > max_reward:\n",
    "            torch.save(model.state_dict(), dpath + 'trained_models/rl_model' + args1.prefix + '.pkl')\n",
    "            max_reward = Re\n",
    "            max_epoch = epoch\n",
    "#         print('Epoch', epoch, Re, t2-t1)\n",
    "    \n",
    "    #load best model parameters from stage 4 and evluate the trained model\n",
    "    model.load_state_dict(torch.load(dpath + 'trained_models/rl_model' + args1.prefix + '.pkl'))\n",
    "    o = 0\n",
    "    l = 0\n",
    "    for batch in tdata:\n",
    "        o += torch.sum(batch[1]).data.item()\n",
    "        l += len(batch[1])\n",
    "    print(o, l, o/l)\n",
    "    t2 = datetime.now()\n",
    "    print('Test Performance - ', i, ': ', model.compute_reward(edata), t2-t1, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['jigsaw-dataset', 'hate-speech-dataset', 'hate-speech-and-offensive-language', 'ami-ibereval-dataset', 'stereotype'])\n"
     ]
    }
   ],
   "source": [
    "print(batched_dsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: 1 hate-speech-dataset\n",
      "Baseline: 59.135914215660776\n",
      "Multi-task: 60.132416603004835\n",
      "RL: 60.33338955416877\n",
      "\n",
      "\n",
      "Task ID: 2 hate-speech-and-offensive-language\n",
      "Baseline: 48.330148764224106\n",
      "Multi-task: 47.100267438651144\n",
      "RL: 47.20860623456615\n",
      "\n",
      "\n",
      "Task ID: 3 ami-ibereval-dataset\n",
      "Baseline: 63.15867345860371\n",
      "Multi-task: 63.93407142262549\n",
      "RL: 62.534722222222214\n",
      "\n",
      "\n",
      "Task ID: 4 stereotype\n",
      "Baseline: 63.707305154804715\n",
      "Multi-task: 67.87178307690164\n",
      "RL: 68.20354359523967\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(trimmed_dsets)):\n",
    "    dset = trimmed_dsets[i]\n",
    "    args1.class_tasks = [class_tasks[i]]\n",
    "    args1.class_types = [class_types[i]]\n",
    "    args1.loss_weights = [loss_weights[i]]\n",
    "    args1.num_tasks = 1\n",
    "    \n",
    "    print('Task ID:', i, list(batched_dsets.keys())[i])\n",
    "    with torch.cuda.device(cuda_device) and torch.no_grad():\n",
    "        tdata = dset[2]\n",
    "        \n",
    "        args2.sizes[-1] = class_tasks[i]\n",
    "        args2.loss_weight = loss_weights[i]\n",
    "        model = FeedForward(args2.sizes, args2.use_cuda, args2.lr, args2.momentum, args2.weight_decay, args2.loss_weight)\n",
    "        model.load_state_dict(torch.load(dpath + 'trained_models/base_model' + str(i) + '_' + model_name + '.pkl'))\n",
    "        model.cuda(cuda_device)\n",
    "        print('Baseline:', model.evaluate(tdata)[2][1] * 100)\n",
    "        \n",
    "        model = PolicyNetwork(args1)\n",
    "        model.cuda(cuda_device)\n",
    "\n",
    "        model.load_state_dict(torch.load(dpath + 'trained_models/mtl_model_p2_dset' + str(i) + '_' + model_name + '.pkl'))\n",
    "        print('Multi-task:', model.compute_reward(tdata) * 100)\n",
    "\n",
    "        model.load_state_dict(torch.load(dpath + 'trained_models/rl_model_p4_dset' + str(i) + '_' + model_name + '.pkl'))\n",
    "        print('RL:', model.compute_reward(tdata) * 100)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mturk Annotated Data Zero-Shot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['stereotype-gold-binary', 'stereotype-gold-multilabel'])\n"
     ]
    }
   ],
   "source": [
    "with open(dpath + 'mturk_batched_dsets_multilabel_' + model_name + '_bsz64.pkl', 'rb') as infile:\n",
    "    mturk_batched_dsets = pickle.load(infile)\n",
    "print(mturk_batched_dsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 53.80277617119722\n",
      "Multi-task: 57.00245700245701\n",
      "RL: 56.36545636545638\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset = mturk_batched_dsets['stereotype-gold-binary']\n",
    "args1.class_tasks = [2]\n",
    "args1.class_types = ['classification']\n",
    "#placeholder, not used in inference\n",
    "args1.loss_weights = [loss_weights[-1]]\n",
    "args1.num_tasks = 1\n",
    "i = 4\n",
    "\n",
    "with torch.cuda.device(cuda_device) and torch.no_grad():\n",
    "    tdata = dset[2]\n",
    "\n",
    "    args2.sizes[-1] = 2\n",
    "    #placeholder, not used in inference\n",
    "    args2.loss_weight = loss_weights[-1]\n",
    "    model = FeedForward(args2.sizes, args2.use_cuda, args2.lr, args2.momentum, args2.weight_decay, args2.loss_weight)\n",
    "    model.load_state_dict(torch.load(dpath + 'trained_models/base_model' + str(i) + '_' + model_name + '.pkl'))\n",
    "    model.cuda(cuda_device)\n",
    "    print('Baseline:', model.evaluate(tdata)[2][1] * 100)\n",
    "\n",
    "    model = PolicyNetwork(args1)\n",
    "    model.cuda(cuda_device)\n",
    "\n",
    "    model.load_state_dict(torch.load(dpath + 'trained_models/mtl_model_p2_dset' + str(i) + '_' + model_name + '.pkl'))\n",
    "    print('Multi-task:', model.compute_reward(tdata) * 100)\n",
    "\n",
    "    model.load_state_dict(torch.load(dpath + 'trained_models/rl_model_p4_dset' + str(i) + '_' + model_name + '.pkl'))\n",
    "    print('RL:', model.compute_reward(tdata) * 100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

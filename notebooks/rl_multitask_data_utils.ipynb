{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import h5py\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/scratch1/rpujari/gcr_workspace/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_names = ['jigsaw-dataset', 'hate-speech-dataset', 'hate-speech-and-offensive-language', 'ami-ibereval-dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jigsaw_data(data_path):\n",
    "    train_file = list(csv.reader(open(data_path + '/train.csv')))\n",
    "\n",
    "    train_data = []\n",
    "    labels = {}\n",
    "\n",
    "    for rnum, row in enumerate(train_file):\n",
    "        if rnum == 0:\n",
    "            keys = row\n",
    "            for key in keys[2:]:\n",
    "                labels[key] = set()\n",
    "        else:\n",
    "            eg = {}\n",
    "            for i, val in enumerate(row):\n",
    "                eg[keys[i]] = val\n",
    "                if keys[i] in labels:\n",
    "                    labels[keys[i]].add(val)\n",
    "            train_data.append(eg)\n",
    "\n",
    "\n",
    "    test_file = list(csv.reader(open(data_path + '/test.csv')))\n",
    "    test_labels = list(csv.reader(open(data_path + '/test_labels.csv')))\n",
    "\n",
    "    rnum = 0\n",
    "    test_data = []\n",
    "    tlabels = {}\n",
    "    for row1, row2 in zip(test_file, test_labels):\n",
    "        if rnum == 0:\n",
    "            keys = row1 + row2\n",
    "            for key in row2[1:]:\n",
    "                tlabels[key] = set()\n",
    "        else:\n",
    "            eg = {}\n",
    "            for i, val in enumerate(row1):\n",
    "                eg[keys[i]] = val\n",
    "            for i, val in enumerate(row2):\n",
    "                eg[keys[len(row1) + i]] = val\n",
    "                if keys[len(row1) + i] in tlabels:\n",
    "                    tlabels[keys[len(row1) + i]].add(val)\n",
    "            test_data.append(eg)\n",
    "        rnum += 1\n",
    "        \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hate_speech_data(data_path):\n",
    "    fdata = list(csv.reader(open(data_path + '/annotations_metadata.csv')))\n",
    "    data = []\n",
    "    for rnum, row in enumerate(fdata):\n",
    "        if rnum > 0:\n",
    "            eg = {}\n",
    "            eg['id'] = row[0]\n",
    "            eg['comment_text'] = open(data_path + '/all_files/' + row[0] + '.txt').read().strip()\n",
    "            if row[4] == 'noHate':\n",
    "                eg['hate'] = 0\n",
    "            else:\n",
    "                eg['hate'] = 1\n",
    "            eg['num_contexts'] = row[3]\n",
    "            data.append(eg)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hate_speech_offensive_data(data_path):\n",
    "    fdata = list(csv.reader(open(data_path + 'labeled_data.csv', 'r')))\n",
    "    data = []\n",
    "    for row in fdata[1:]:\n",
    "        eg = {}\n",
    "        eg['comment_text'] = row[-1]\n",
    "        for j, ritem in enumerate(row[1:-1]):\n",
    "            eg[fdata[0][j + 1]] = ritem\n",
    "        data.append(eg)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_misogyny_data(data_path):\n",
    "    fdata = list(csv.reader(open(data_path + '/en_AMI_TrainingSet_NEW.csv', 'r', errors='ignore')))\n",
    "    data = []\n",
    "    for row in fdata[1:]:\n",
    "        eg = {}\n",
    "        eg['comment_text'] = row[1]\n",
    "        for j, ritem in enumerate(row):\n",
    "            if j != 1:\n",
    "                eg[fdata[0][j]] = ritem\n",
    "        data.append(eg)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_data = load_jigsaw_data(dpath + dset_names[0] + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_data = load_hate_speech_data(dpath + dset_names[1] + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hso_data = load_hate_speech_offensive_data(dpath + dset_names[2] + '/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "misogyny_data = load_misogyny_data(dpath + dset_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571 153164 10944 24783 3251\n"
     ]
    }
   ],
   "source": [
    "print(len(js_data[0]), len(js_data[1]), len(hs_data), len(hso_data), len(misogyny_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0000997932d777bf', 'comment_text': \"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\", 'toxic': '0', 'severe_toxic': '0', 'obscene': '0', 'threat': '0', 'insult': '0', 'identity_hate': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(js_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'misogyny'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-9f13a6231d88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjs_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'misogyny'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'identity_hate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'misogyny'"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for eg in js_data[0]:\n",
    "    if eg['misogyny'] == '1' and eg['identity_hate'] == '1':\n",
    "        print(eg['comment_text'])\n",
    "        x += 1\n",
    "        if x == 30:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embedding Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351713\n"
     ]
    }
   ],
   "source": [
    "all_sents = []\n",
    "for eg in js_data[0]:\n",
    "    all_sents.append(eg['comment_text'])\n",
    "for eg in js_data[1]:\n",
    "    all_sents.append(eg['comment_text'])\n",
    "for eg in hs_data:\n",
    "    all_sents.append(eg['comment_text'])\n",
    "for eg in hso_data:\n",
    "    all_sents.append(eg['comment_text'])\n",
    "for eg in misogyny_data:\n",
    "    all_sents.append(eg['comment_text'])\n",
    "print(len(all_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'sample_bert-base-uncased_embs.pkl', 'rb') as infile:\n",
    "    bert_base_embs = pickle.load(infile)\n",
    "\n",
    "print(bert_base_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = nn.CosineSimilarity(dim=0)\n",
    "def find_sent(emb):\n",
    "    for i in range(bert_base_embs.size(0)):\n",
    "        csim = cos_sim(emb, bert_base_embs[i, :])\n",
    "        if 1 - csim <= 1e-08:\n",
    "            print(i, all_sents[i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7785 user:ihaveapickle  user:208.113.241.125  \n",
      "I do infer that these are the same person, & that this person is a  vandal, & that this person is not demonstrating any capability other than  vandalism.\n",
      "\n",
      "[[ hopiakuta  Please do  sign  your  signature  on your  message.  %7e%7e   Thank You. -]]\n"
     ]
    }
   ],
   "source": [
    "find_sent(bert_base_embs[7785, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlnet-large-cased'\n",
    "tokenizer_class = XLNetTokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "with torch.cuda.device(0):\n",
    "    with torch.no_grad():\n",
    "        model = XLNetModel.from_pretrained(model_name,\\\n",
    "                                          output_hidden_states=False,\\\n",
    "                                          output_attentions=False)\n",
    "        model.eval()\n",
    "        model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_emb(all_sents):\n",
    "    if len(all_sents) > 0:\n",
    "        with torch.cuda.device(0):\n",
    "            all_toks = tokenizer.batch_encode_plus(all_sents, padding=True,\\\n",
    "                                                   add_special_tokens=True)\n",
    "            torch.cuda.empty_cache()\n",
    "            tok_tensor = torch.tensor([l[:512] for l in all_toks['input_ids']]).to('cuda')\n",
    "            with torch.no_grad():\n",
    "                all_doc_tensor = model(tok_tensor)['last_hidden_state']\n",
    "                all_doc_tensor.to('cpu')\n",
    "            all_attn_mask = torch.tensor(all_toks['attention_mask'])\n",
    "            ret_tensor = torch.FloatTensor(all_doc_tensor.size(0), all_doc_tensor.size(-1))\n",
    "            for i in range(all_doc_tensor.size(0)):\n",
    "                slen = torch.sum(all_attn_mask[i, :])\n",
    "                ret_tensor[i, :] = torch.mean(all_doc_tensor[i, :slen, :], dim=0)\n",
    "            del tok_tensor\n",
    "            del all_doc_tensor\n",
    "            del all_attn_mask\n",
    "            torch.cuda.empty_cache()\n",
    "            return ret_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_bert_embs(all_sents, save_path=None, bsz=50):\n",
    "    b = 0\n",
    "    e = bsz\n",
    "    ret_vecs = []\n",
    "    t1 = datetime.now()\n",
    "    while b < len(all_sents):\n",
    "        batch_sents = all_sents[b:e]\n",
    "        out_tensor = create_bert_emb(batch_sents)\n",
    "        ret_vecs.append(out_tensor)\n",
    "        b += bsz\n",
    "        e += bsz\n",
    "        if b % 500 == 0:\n",
    "            t2 = datetime.now()\n",
    "            print(b, 'done', t2 - t1)\n",
    "            if save_path:\n",
    "                with open(save_path, 'wb') as outfile:\n",
    "                    pickle.dump(ret_vecs, outfile)\n",
    "    ret_vec = torch.cat(ret_vecs, dim=0)\n",
    "    if save_path:\n",
    "        with open(save_path, 'wb') as outfile:\n",
    "            pickle.dump(ret_vec, outfile)\n",
    "    return ret_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Takes approx. 2 hr 40 mins to finish\n",
    "sample_bert_embs = create_batch_bert_embs(all_sents, save_path=dpath + 'sample_' + model_name + '_embs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = 0\n",
    "with open(dpath + dset_names[0] + '/' + model_name + '_embs_train.pkl', 'wb') as outfile:\n",
    "    pickle.dump(sample_bert_embs[rc:rc+len(js_data[0]), :], outfile)\n",
    "rc += len(js_data[0])\n",
    "with open(dpath + dset_names[0] + '/' + model_name + '_embs_test.pkl', 'wb') as outfile:\n",
    "    pickle.dump(sample_bert_embs[rc:rc+len(js_data[1]), :], outfile)\n",
    "rc += len(js_data[1])\n",
    "with open(dpath + dset_names[1] + '/' + model_name + '_embs.pkl', 'wb') as outfile:\n",
    "    pickle.dump(sample_bert_embs[rc:rc+len(hs_data), :], outfile)\n",
    "rc += len(hs_data)\n",
    "with open(dpath + dset_names[2] + '/' + model_name + '_embs.pkl', 'wb') as outfile:\n",
    "    pickle.dump(sample_bert_embs[rc:rc+len(hso_data), :], outfile)\n",
    "rc += len(hso_data)\n",
    "with open(dpath + dset_names[0] + '/' + model_name + '_embs.pkl', 'wb') as outfile:\n",
    "    pickle.dump(sample_bert_embs[rc:rc+len(misogyny_data)], outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereoset Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number = 1\n",
    "data_tuples = json.load(open(dpath + 'stereoset/simulated_data/blank_split_' + str(batch_number) + '.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_sents = []\n",
    "for i, data_eg in enumerate(data_tuples):\n",
    "    inp = data_eg['input']\n",
    "    comp = data_eg['suggestion']\n",
    "    data_sents.append(inp.strip() + ' ' + comp.strip())\n",
    "print(len(data_sents))\n",
    "data_bert_embs = create_batch_bert_embs(data_sents)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'stereoset/simulated_data/split_' + str(batch_number) + '_' + model_name + '_data_embs.pkl', 'wb') as outfile:\n",
    "    pickle.dump(data_bert_embs, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Batched Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'sample_' + model_name + '_embs.pkl', 'rb') as infile:\n",
    "    sample_bert_embs = pickle.load(infile)\n",
    "print(sample_bert_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'stereoset/simulated_data/split_' + str(batch_number) + '_' + model_name + '_data_embs.pkl', 'rb') as infile:\n",
    "    data_bert_embs = pickle.load(infile)\n",
    "print(data_bert_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4056)\n",
    "train_x = []\n",
    "train_y = []\n",
    "dev_x = []\n",
    "dev_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "for i, data_eg in enumerate(data_tuples):\n",
    "    inp = data_eg['input']\n",
    "    comp = data_eg['suggestion']\n",
    "    label = data_eg['label']\n",
    "    if label == 'stereotype':\n",
    "        dy = torch.from_numpy(np.ones((1, 1), dtype=int))\n",
    "    else:\n",
    "        dy = torch.from_numpy(np.zeros((1, 1), dtype=int))\n",
    "\n",
    "    dx = data_bert_embs[i, :].view(1, -1)\n",
    "    toss = random.random()\n",
    "    \n",
    "    if toss <= 0.7:\n",
    "        train_x.append(dx)\n",
    "        train_y.append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        dev_x.append(dx)\n",
    "        dev_y.append(dy)\n",
    "    else:\n",
    "        test_x.append(dx)\n",
    "        test_y.append(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_data(data_x, data_y, task_type='classification', batch_size=64):\n",
    "    b = 0\n",
    "    e = batch_size\n",
    "    data_batches = []\n",
    "    y_dim = data_y[0].size(-1)\n",
    "    while b < len(data_x):\n",
    "        data_x[b:e]\n",
    "        d_X = torch.cat(data_x[b:e], dim=0).float()\n",
    "        if task_type == 'classification':\n",
    "            d_Y = torch.cat(data_y[b:e], dim=0).view(-1).long()\n",
    "        elif task_type == 'multilabel':\n",
    "            d_Y = torch.cat(data_y[b:e], dim=0).view(-1, y_dim).float()\n",
    "        data_batches.append((d_X, d_Y))\n",
    "        b += batch_size\n",
    "        e += batch_size\n",
    "    return data_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_tr_batches = batchify_data(train_x, train_y)\n",
    "ss_de_batches = batchify_data(dev_x, dev_y)\n",
    "ss_te_batches = batchify_data(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating multi-label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "random.seed(4056)\n",
    "dsets = {}\n",
    "\n",
    "#jigsaw data\n",
    "dset_name = dset_names[0]\n",
    "dsets[dset_name] = {}\n",
    "dsets[dset_name]['train'] = ([], [])\n",
    "dsets[dset_name]['dev'] = ([], [])\n",
    "dsets[dset_name]['test'] = ([], [])\n",
    "dset_labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for eg in js_data[0]:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, len(dset_labels)), dtype=int))\n",
    "    for lnum, label in enumerate(dset_labels):\n",
    "        if int(eg[label]) > 0:\n",
    "            dy[0, lnum] = 1\n",
    "    toss = random.random()\n",
    "    if toss <= 0.8:\n",
    "        dsets[dset_name]['train'][0].append(dx)\n",
    "        dsets[dset_name]['train'][1].append(dy)\n",
    "    else:\n",
    "        dsets[dset_name]['dev'][0].append(dx)\n",
    "        dsets[dset_name]['dev'][1].append(dy)\n",
    "    i += 1\n",
    "\n",
    "for eg in js_data[1]:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, len(dset_labels)), dtype=int))\n",
    "    for lnum, label in enumerate(dset_labels):\n",
    "        if int(eg[label]) > 0:\n",
    "            dy[0, lnum] = 1        \n",
    "    dsets[dset_name]['test'][0].append(dx)\n",
    "    dsets[dset_name]['test'][1].append(dy)\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "#hate-speech data\n",
    "dset_name = dset_names[1]\n",
    "dsets[dset_name] = {}\n",
    "dsets[dset_name]['train'] = ([], [])\n",
    "dsets[dset_name]['dev'] = ([], [])\n",
    "dsets[dset_name]['test'] = ([], [])\n",
    "dset_labels = ['hate']\n",
    "for eg in hs_data:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, len(dset_labels)), dtype=int))\n",
    "    for lnum, label in enumerate(dset_labels):\n",
    "        if int(eg[label]) > 0:\n",
    "            dy[0, lnum] = 1\n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        dsets[dset_name]['train'][0].append(dx)\n",
    "        dsets[dset_name]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        dsets[dset_name]['dev'][0].append(dx)\n",
    "        dsets[dset_name]['dev'][1].append(dy)\n",
    "    else:\n",
    "        dsets[dset_name]['test'][0].append(dx)\n",
    "        dsets[dset_name]['test'][1].append(dy)\n",
    "    i += 1\n",
    "    \n",
    "#hate-speech-and-offensive data\n",
    "dset_name = dset_names[2]\n",
    "dsets[dset_name] = {}\n",
    "dsets[dset_name]['train'] = ([], [])\n",
    "dsets[dset_name]['dev'] = ([], [])\n",
    "dsets[dset_name]['test'] = ([], [])\n",
    "dset_labels = ['class']\n",
    "for eg in hso_data:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, len(dset_labels)), dtype=int))\n",
    "    for lnum, label in enumerate(dset_labels):\n",
    "        if int(eg[label]) > 0:\n",
    "            dy[0, lnum] = int(eg[label])\n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        dsets[dset_name]['train'][0].append(dx)\n",
    "        dsets[dset_name]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        dsets[dset_name]['dev'][0].append(dx)\n",
    "        dsets[dset_name]['dev'][1].append(dy)\n",
    "    else:\n",
    "        dsets[dset_name]['test'][0].append(dx)\n",
    "        dsets[dset_name]['test'][1].append(dy) \n",
    "    i += 1\n",
    "\n",
    "#misogyny data\n",
    "dset_name = dset_names[3]\n",
    "dsets[dset_name] = {}\n",
    "dsets[dset_name]['train'] = ([], [])\n",
    "dsets[dset_name]['dev'] = ([], [])\n",
    "dsets[dset_name]['test'] = ([], [])\n",
    "dset_labels = ['misogynous']\n",
    "for eg in misogyny_data:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, len(dset_labels)), dtype=int))\n",
    "    for lnum, label in enumerate(dset_labels):\n",
    "        if int(eg[label]) > 0:\n",
    "            dy[0, lnum] = 1\n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        dsets[dset_name]['train'][0].append(dx)\n",
    "        dsets[dset_name]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        dsets[dset_name]['dev'][0].append(dx)\n",
    "        dsets[dset_name]['dev'][1].append(dy)\n",
    "    else:\n",
    "        dsets[dset_name]['test'][0].append(dx)\n",
    "        dsets[dset_name]['test'][1].append(dy)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dsets = {}\n",
    "for label in dsets:\n",
    "    if label == 'jigsaw-dataset':\n",
    "        tr_batches = batchify_data(dsets[label]['train'][0], dsets[label]['train'][1], task_type='multilabel')\n",
    "        de_batches = batchify_data(dsets[label]['dev'][0], dsets[label]['dev'][1], task_type='multilabel')\n",
    "        te_batches = batchify_data(dsets[label]['test'][0], dsets[label]['test'][1], task_type='multilabel')\n",
    "    else:\n",
    "        tr_batches = batchify_data(dsets[label]['train'][0], dsets[label]['train'][1], task_type='classification')\n",
    "        de_batches = batchify_data(dsets[label]['dev'][0], dsets[label]['dev'][1], task_type='classification')\n",
    "        te_batches = batchify_data(dsets[label]['test'][0], dsets[label]['test'][1], task_type='classification')\n",
    "    batched_dsets[label] = (tr_batches, de_batches, te_batches)\n",
    "batched_dsets['stereotype'] = (ss_tr_batches, ss_de_batches, ss_te_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'batched_dsets_multilabel_' + model_name + 'bsz64.pkl', 'wb') as outfile:\n",
    "    pickle.dump(batched_dsets, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batched_dsets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating binary-label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "random.seed(4056)\n",
    "dsets = {}\n",
    "\n",
    "for eg in js_data[0]:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    for label in eg:\n",
    "        if label not in ['id', 'comment_text']:\n",
    "            if label not in dsets:\n",
    "                dsets[label] = {}\n",
    "                dsets[label]['train'] = ([], [])\n",
    "                dsets[label]['dev'] = ([], [])\n",
    "                dsets[label]['test'] = ([], [])\n",
    "            if eg[label] == 1:\n",
    "                dy = torch.from_numpy(np.ones((1, 1), dtype=int))\n",
    "            else:\n",
    "                dy = torch.from_numpy(np.zeros((1, 1), dtype=int))\n",
    "            toss = random.random()\n",
    "            if toss <= 0.7:\n",
    "                dsets[label]['train'][0].append(dx)\n",
    "                dsets[label]['train'][1].append(dy)\n",
    "            elif toss <= 0.85:\n",
    "                dsets[label]['dev'][0].append(dx)\n",
    "                dsets[label]['dev'][1].append(dy)\n",
    "            else:\n",
    "                dsets[label]['test'][0].append(dx)\n",
    "                dsets[label]['test'][1].append(dy)\n",
    "    i += 1\n",
    "\n",
    "for eg in js_data[1]:\n",
    "    i += 1\n",
    "    \n",
    "for eg in hs_data:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    for label in eg:\n",
    "        if label not in ['id', 'comment_text', 'num_contexts']:\n",
    "            if label not in dsets:\n",
    "                dsets[label] = {}\n",
    "                dsets[label]['train'] = ([], [])\n",
    "                dsets[label]['dev'] = ([], [])\n",
    "                dsets[label]['test'] = ([], [])\n",
    "            if eg[label] == 1:\n",
    "                dy = torch.from_numpy(np.ones((1, 1), dtype=int))\n",
    "            else:\n",
    "                dy = torch.from_numpy(np.zeros((1, 1), dtype=int))\n",
    "            toss = random.random()\n",
    "            if toss <= 0.7:\n",
    "                dsets[label]['train'][0].append(dx)\n",
    "                dsets[label]['train'][1].append(dy)\n",
    "            elif toss <= 0.85:\n",
    "                dsets[label]['dev'][0].append(dx)\n",
    "                dsets[label]['dev'][1].append(dy)\n",
    "            else:\n",
    "                dsets[label]['test'][0].append(dx)\n",
    "                dsets[label]['test'][1].append(dy)\n",
    "    i += 1\n",
    "    \n",
    "label = 'hate_speech_offensive'\n",
    "dsets[label] = {}\n",
    "dsets[label]['train'] = ([], [])\n",
    "dsets[label]['dev'] = ([], [])\n",
    "dsets[label]['test'] = ([], [])\n",
    "for eg in hso_data:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.ones((1, 1), dtype=int))\n",
    "    dy[0, 0] = int(eg['class'])\n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        dsets[label]['train'][0].append(dx)\n",
    "        dsets[label]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        dsets[label]['dev'][0].append(dx)\n",
    "        dsets[label]['dev'][1].append(dy)\n",
    "    else:\n",
    "        dsets[label]['test'][0].append(dx)\n",
    "        dsets[label]['test'][1].append(dy)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "label = 'misogyny'\n",
    "dsets[label] = {}\n",
    "dsets[label]['train'] = ([], [])\n",
    "dsets[label]['dev'] = ([], [])\n",
    "dsets[label]['test'] = ([], [])\n",
    "for eg in misogyny_data:\n",
    "    dx = sample_bert_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.ones((1, 1), dtype=int))\n",
    "    dy[0, 0] = int(eg['misogynous'])\n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        dsets[label]['train'][0].append(dx)\n",
    "        dsets[label]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        dsets[label]['dev'][0].append(dx)\n",
    "        dsets[label]['dev'][1].append(dy)\n",
    "    else:\n",
    "        dsets[label]['test'][0].append(dx)\n",
    "        dsets[label]['test'][1].append(dy)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dsets = {}\n",
    "for label in dsets:\n",
    "    tr_batches = batchify_data(dsets[label]['train'][0], dsets[label]['train'][1])\n",
    "    de_batches = batchify_data(dsets[label]['dev'][0], dsets[label]['dev'][1])\n",
    "    te_batches = batchify_data(dsets[label]['test'][0], dsets[label]['test'][1])\n",
    "    batched_dsets[label] = (tr_batches, de_batches, te_batches)\n",
    "batched_dsets['stereotype'] = (ss_tr_batches, ss_de_batches, ss_te_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'batched_dsets.pkl', 'wb') as outfile:\n",
    "    pickle.dump(batched_dsets, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(batched_dsets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTurk Annotated Data Processing and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = list(csv.reader(open(dpath + 'mturk_annotation/mturk_batch1_output.csv', 'r')))\n",
    "f2 = list(csv.reader(open(dpath + 'mturk_annotation/mturk_batch2_output.csv', 'r')))\n",
    "f3 = list(csv.reader(open(dpath + 'mturk_annotation/mturk_batch3_output.csv', 'r')))\n",
    "f4 = list(csv.reader(open(dpath + 'mturk_annotation/filtered_batch1_output.csv', 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'Stereotype', 'Stereotype-Anns']\n",
      "['S.No.', 'Input Text', 'Stereotype-Majority', 'Popularity-Majority', 'Fakeness-Majority', 'Stereotypical Association-Majority', 'Stereotype', 'Popularity', 'Fakeness', 'Stereotypical Association']\n",
      "['Text', 'Intentional-Stereotype', 'Unintentional-Association', 'Stereotype-Anns', 'Association-Anns']\n",
      "['Text', 'Intentional-Stereotype', 'Unintentional-Association', 'Stereotype-Anns', 'Association-Anns']\n"
     ]
    }
   ],
   "source": [
    "print(f1[0])\n",
    "print(f2[0])\n",
    "print(f3[0])\n",
    "print(f4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for row in f1[1:]:\n",
    "    data[row[0]] = (row[1], 'no')\n",
    "for row in f2[1:]:\n",
    "    data[row[1]] = (row[2], row[5])\n",
    "for row in f3[1:]:\n",
    "    data[row[0]] = (row[1], row[2])\n",
    "for row in f4[1:]:\n",
    "    data[row[0]] = (row[1], row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_data = {}\n",
    "for sent in data:\n",
    "    if data[sent][0] not in ['yes', 'no'] or data[sent][1] not in ['yes', 'no']:\n",
    "        pass\n",
    "#         print(sent)\n",
    "##  Uncomment to self-annotate examples that don't have agreement\n",
    "#         a1 = data[sent][0]\n",
    "#         a2 = data[sent][1]\n",
    "#         if data[sent][0] not in ['yes', 'no']:\n",
    "#             a1 = input('Explicit?: ')\n",
    "#         if data[sent][1] not in ['yes', 'no']:\n",
    "#             a2 = input('Implicit?: ')\n",
    "#         filt_data[sent] = (a1, a2)\n",
    "    else:\n",
    "        filt_data[sent] = data[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 282 1197\n"
     ]
    }
   ],
   "source": [
    "# print(len(filt_data))\n",
    "s = 0\n",
    "u = 0\n",
    "n = 0\n",
    "i = 1\n",
    "f1 = open('annotated_data.csv', 'w')\n",
    "fw = csv.writer(f1)\n",
    "fw.writerow(['S. No.', 'Text', 'Explicit Stereotype?', 'Implicit Stereotypical Association?'])\n",
    "for sent in filt_data:\n",
    "    if filt_data[sent][0] == 'yes':\n",
    "        s += 1\n",
    "    if filt_data[sent][1] == 'yes':\n",
    "        u += 1\n",
    "    if filt_data[sent][0] == 'no' and filt_data[sent][1] == 'no':\n",
    "        n += 1\n",
    "    fw.writerow([i, sent, filt_data[sent][0], filt_data[sent][1]])\n",
    "    i += 1\n",
    "f1.close()\n",
    "print(s, u, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 done 0:00:02.178143\n",
      "1000 done 0:00:04.172780\n",
      "1500 done 0:00:06.507899\n",
      "2000 done 0:00:08.773296\n"
     ]
    }
   ],
   "source": [
    "#run the model loading and function definition files from 'BERT Embedding Computation' section before running this cell\n",
    "all_sents = []\n",
    "for sent in filt_data:\n",
    "    all_sents.append(sent)\n",
    "#     print(sent)\n",
    "all_embs = create_batch_bert_embs(all_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stereotype-gold data binary classification task data tensor generation\n",
    "mturk_dsets = {}\n",
    "dset_name = 'stereotype-gold-binary'\n",
    "mturk_dsets[dset_name] = {}\n",
    "mturk_dsets[dset_name]['train'] = ([], [])\n",
    "mturk_dsets[dset_name]['dev'] = ([], [])\n",
    "mturk_dsets[dset_name]['test'] = ([], [])\n",
    "\n",
    "i = 0\n",
    "for eg in all_sents:\n",
    "    dx = all_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, 1), dtype=int))\n",
    "                          \n",
    "    if filt_data[eg][0] == 'yes' or filt_data[eg][1] == 'yes':\n",
    "        dy[0, 0] = 1\n",
    "                        \n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        mturk_dsets[dset_name]['train'][0].append(dx)\n",
    "        mturk_dsets[dset_name]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        mturk_dsets[dset_name]['dev'][0].append(dx)\n",
    "        mturk_dsets[dset_name]['dev'][1].append(dy)\n",
    "    else:\n",
    "        mturk_dsets[dset_name]['test'][0].append(dx)\n",
    "        mturk_dsets[dset_name]['test'][1].append(dy)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stereotype-gold data multilabel task data tensor generation\n",
    "dset_name = 'stereotype-gold-multilabel'\n",
    "mturk_dsets[dset_name] = {}\n",
    "mturk_dsets[dset_name]['train'] = ([], [])\n",
    "mturk_dsets[dset_name]['dev'] = ([], [])\n",
    "mturk_dsets[dset_name]['test'] = ([], [])\n",
    "\n",
    "i = 0\n",
    "for eg in all_sents:\n",
    "    dx = all_embs[i, :].view(1, -1)\n",
    "    dy = torch.from_numpy(np.zeros((1, 2), dtype=int))\n",
    "                          \n",
    "    if filt_data[eg][0] == 'yes':\n",
    "        dy[0, 0] = 1\n",
    "    if filt_data[eg][1] == 'yes':\n",
    "        dy[0, 1] = 1\n",
    "                        \n",
    "    toss = random.random()\n",
    "    if toss <= 0.7:\n",
    "        mturk_dsets[dset_name]['train'][0].append(dx)\n",
    "        mturk_dsets[dset_name]['train'][1].append(dy)\n",
    "    elif toss <= 0.85:\n",
    "        mturk_dsets[dset_name]['dev'][0].append(dx)\n",
    "        mturk_dsets[dset_name]['dev'][1].append(dy)\n",
    "    else:\n",
    "        mturk_dsets[dset_name]['test'][0].append(dx)\n",
    "        mturk_dsets[dset_name]['test'][1].append(dy)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run batchify_data() from 'Create Batched Datasets' section before running this cell\n",
    "mturk_batched_dsets = {}\n",
    "for label in mturk_dsets:\n",
    "    if label.endswith('multilabel'):\n",
    "        tr_batches = batchify_data(mturk_dsets[label]['train'][0], mturk_dsets[label]['train'][1], task_type='multilabel')\n",
    "        de_batches = batchify_data(mturk_dsets[label]['dev'][0], mturk_dsets[label]['dev'][1], task_type='multilabel')\n",
    "        te_batches = batchify_data(mturk_dsets[label]['test'][0], mturk_dsets[label]['test'][1], task_type='multilabel')\n",
    "    else:\n",
    "        tr_batches = batchify_data(mturk_dsets[label]['train'][0], mturk_dsets[label]['train'][1], task_type='classification')\n",
    "        de_batches = batchify_data(mturk_dsets[label]['dev'][0], mturk_dsets[label]['dev'][1], task_type='classification')\n",
    "        te_batches = batchify_data(mturk_dsets[label]['test'][0], mturk_dsets[label]['test'][1], task_type='classification')\n",
    "    mturk_batched_dsets[label] = (tr_batches, de_batches, te_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dpath + 'mturk_batched_dsets_multilabel_' + model_name + '_bsz64.pkl', 'wb') as outfile:\n",
    "    pickle.dump(mturk_batched_dsets, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
